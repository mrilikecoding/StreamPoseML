{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import StreamPoseML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install stream_pose_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set input and output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "# Inputs\n",
    "example_input_directory = \"../../example_data/input\"\n",
    "example_output_directory = f\"../../example_data/output-{time.time_ns()}\"\n",
    "\n",
    "source_annotations_directory = os.path.join(example_input_directory, \"source_annotations\")\n",
    "source_videos_directory = os.path.join(example_input_directory, \"source_videos\")\n",
    "\n",
    "# Outputs\n",
    "\n",
    "# The location to output sequence data\n",
    "sequence_data_directory = os.path.join(example_output_directory, \"sequences\")\n",
    "\n",
    "# The location to output keypoint data\n",
    "keypoints_data_directory = os.path.join(example_output_directory, \"keypoints\")\n",
    "\n",
    "# The location to output datasets\n",
    "merged_annotation_output_directory = os.path.join(example_output_directory, \"datasets\")\n",
    "\n",
    "# The place to save trained models\n",
    "trained_models_output_directory = os.path.join(example_output_directory, \"trained_models\")\n",
    "\n",
    "\n",
    "for dir in [sequence_data_directory, keypoints_data_directory, merged_annotation_output_directory, trained_models_output_directory]:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Keypoints and Sequence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import stream_pose_ml.jobs.process_videos_job as pv\n",
    "\n",
    "folder = f\"run-preproccessed-{time.time_ns()}\"  \n",
    "keypoints_path = f\"{keypoints_data_directory}/{folder}\"\n",
    "sequence_path = f\"{sequence_data_directory}/{folder}\"\n",
    "\n",
    "data = pv.ProcessVideosJob().process_videos(\n",
    "    src_videos_path=source_videos_directory,\n",
    "    output_keypoints_data_path=keypoints_path,\n",
    "    output_sequence_data_path=sequence_path,\n",
    "    write_keypoints_to_file=True,\n",
    "    write_serialized_sequence_to_file=True,\n",
    "    limit=None,\n",
    "    configuration={},\n",
    "    preprocess_video=True,\n",
    "    return_output=False\n",
    ")\n",
    "\n",
    "print(f\"Generated keypoints are located at {data['keypoints_path']}\")\n",
    "print(f\"Generated sequences are located at {data['sequence_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge video sequence data into a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stream_pose_ml.jobs.build_and_format_dataset_job as data_builder \n",
    "\n",
    "db = data_builder.BuildAndFormatDatasetJob()\n",
    "\n",
    "dataset_file_name = \"preprocessed_flatten_on_example_10_frames_5\"\n",
    "\n",
    "dataset = db.build_dataset_from_data_files(\n",
    "    annotations_data_directory=source_annotations_directory,\n",
    "    sequence_data_directory=sequence_data_directory,\n",
    "    limit=None,\n",
    ")\n",
    "\n",
    "formatted_dataset = db.format_dataset(\n",
    "    dataset=dataset,\n",
    "    pool_frame_data_by_clip=False,\n",
    "    decimal_precision=4,\n",
    "    include_unlabeled_data=True,\n",
    "    include_angles=True,\n",
    "    include_distances=True,\n",
    "    include_normalized=True,\n",
    "    segmentation_strategy=\"flatten_into_columns\",\n",
    "    segmentation_splitter_label=\"step_type\",\n",
    "    segmentation_window=10,\n",
    "    segmentation_window_label=\"weight_transfer_type\",\n",
    ")\n",
    "\n",
    "db.write_dataset_to_csv(\n",
    "    csv_location=merged_annotation_output_directory,\n",
    "    formatted_dataset=formatted_dataset,\n",
    "    filename=dataset_file_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model (Gradient Boost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create some synthetic data from our limited sample data for training demo purposes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our dataset example is comically small, so let's make it bigger for the sake of a training demonstration\n",
    "\n",
    "import pandas as pd\n",
    "data_file = os.path.join(merged_annotation_output_directory, f\"{dataset_file_name}.csv\")\n",
    "data_file_expanded = os.path.join(merged_annotation_output_directory, f\"{dataset_file_name}-EXPANDED.csv\")\n",
    "\n",
    "df = pd.read_csv(data_file)\n",
    "df = pd.concat( map(pd.read_csv, [data_file for _ in range(100)]), ignore_index=True) \n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.to_csv(data_file_expanded)\n",
    "\n",
    "display(len(df))\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE This example will be very overfit!\n",
    "from stream_pose_ml.learning import model_builder as mb\n",
    "\n",
    "# Mapping string categories to numerical\n",
    "value_map = {\n",
    "    \"weight_transfer_type\": {\n",
    "        \"Failure Weight Transfer\": 0,\n",
    "        \"Successful Weight Transfer\": 1,\n",
    "    },\n",
    "    \"step_type\": {\n",
    "        \"Left Step\": 0,\n",
    "        \"Right Step\": 1,\n",
    "    },\n",
    "}\n",
    "# Columns we know we'll always want to drop\n",
    "drop_list = [\"video_id\", \"step_frame_id\", \"frame_number\", \"step_type\"]\n",
    "# Only keep these columns (including target)\n",
    "column_whitelist = []\n",
    "\n",
    "\n",
    "model_builder = mb.ModelBuilder()\n",
    "\n",
    "model_builder.load_and_prep_dataset_from_csv(\n",
    "    path=data_file_expanded,\n",
    "    target=\"weight_transfer_type\",\n",
    "    value_map=value_map,\n",
    "    column_whitelist=column_whitelist,\n",
    "    drop_list=drop_list,\n",
    ")\n",
    "\n",
    "model_builder.set_train_test_split(\n",
    "    balance_off_target=True,\n",
    "    upsample_minority=True,\n",
    "    downsample_majority=False,\n",
    "    use_SMOTE=False,\n",
    "    random_state=40002,\n",
    ")\n",
    "model_builder.train_gradient_boost()\n",
    "model_builder.evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "# NOTE This example will be very overfit!\n",
    "from stream_pose_ml.learning import model_builder as mb\n",
    "\n",
    "# Mapping string categories to numerical\n",
    "value_map = {\n",
    "    \"weight_transfer_type\": {\n",
    "        \"Failure Weight Transfer\": 0,\n",
    "        \"Successful Weight Transfer\": 1,\n",
    "    },\n",
    "    \"step_type\": {\n",
    "        \"Left Step\": 0,\n",
    "        \"Right Step\": 1,\n",
    "    },\n",
    "}\n",
    "# Columns we know we'll always want to drop\n",
    "drop_list = [\"video_id\", \"step_frame_id\", \"frame_number\", \"step_type\"]\n",
    "# Only keep these columns (including target)\n",
    "column_whitelist = []\n",
    "\n",
    "model_builder.load_and_prep_dataset_from_csv(\n",
    "    path=data_file_expanded,\n",
    "    target=\"weight_transfer_type\",\n",
    "    value_map=value_map,\n",
    "    column_whitelist=column_whitelist,\n",
    "    drop_list=drop_list,\n",
    ")\n",
    "\n",
    "model_builder.set_train_test_split(\n",
    "    balance_off_target=True,\n",
    "    upsample_minority=True,\n",
    "    downsample_majority=False,\n",
    "    use_SMOTE=False,\n",
    "    random_state=40002,\n",
    ")\n",
    "# model_builder.run_pca(num_components=200)\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\": [randint(400, 600)],\n",
    "    \"max_depth\": [randint(9, 15)],\n",
    "    \"max_features\": [randint(4, 12)],\n",
    "}\n",
    "rf_params = {\n",
    "    \"n_estimators\": [20,50,100,200],\n",
    "    \"max_depth\": 9,\n",
    "    \"max_leaf_nodes\": 63,\n",
    "}\n",
    "\n",
    "model_builder.train_random_forest(\n",
    "    use_random_search=True, \n",
    "    params=rf_params, \n",
    "    param_dist=param_dist, \n",
    "    iterations=50, \n",
    "    random_state = 123\n",
    ")\n",
    "model_builder.evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model for use in the Web Application\n",
    "\n",
    "This will ouput a pickled dictionary with the model saved to the \"classifier\" key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" WRITE NOTES ON THIS RUN HERE \"\"\"\n",
    "notes = \"\"\"\n",
    "Gradient Boost classifier (90% ROC AUC) trained on dataset preprocessed_flatten_on_example_10_frames, a 10 frame window with flat column 2d angles + distances, and randomly upsampled\n",
    "    \"\"\"\n",
    "\n",
    "model_builder.save_model_and_datasets(notes=notes, model_type=\"gradient-boost\", model_path=trained_models_output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other kinds of datasets from sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset with raw x, y, z joint data, with one frame per row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_data_directory = \"../../data/sequences/run-preproccessed-1680117203184086000\"\n",
    "db = data_builder.BuildAndFormatDatasetJob()\n",
    "dataset = db.build_dataset_from_data_files(\n",
    "    annotations_data_directory=source_annotations_directory,\n",
    "    sequence_data_directory=sequence_data_directory,\n",
    "    limit=None,\n",
    ")\n",
    "\n",
    "formatted_dataset = db.format_dataset(\n",
    "    dataset=dataset,\n",
    "    pool_frame_data_by_clip=False,\n",
    "    decimal_precision=4,\n",
    "    include_unlabeled_data=True,\n",
    "    include_joints=True,\n",
    "    include_z_axis=True,\n",
    "    include_angles=False,\n",
    "    include_distances=False,\n",
    "    include_normalized=False,\n",
    "    segmentation_strategy=\"none\",\n",
    ")\n",
    "\n",
    "db.write_dataset_to_csv(\n",
    "    csv_location=merged_annotation_output_directory,\n",
    "    formatted_dataset=formatted_dataset,\n",
    "    filename=\"preprocessed_frame_joint_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split on Step Type, pooled temporal dynamics with angles and distances, only the last 10 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = data_builder.BuildAndFormatDatasetJob()\n",
    "dataset = db.build_dataset_from_data_files(\n",
    "    annotations_data_directory=source_annotations_directory,\n",
    "    sequence_data_directory=sequence_data_directory,\n",
    "    limit=None,\n",
    ")\n",
    "\n",
    "formatted_dataset = db.format_dataset(\n",
    "    dataset=dataset,\n",
    "    pool_frame_data_by_clip=True,\n",
    "    decimal_precision=4,\n",
    "    include_unlabeled_data=True,\n",
    "    include_angles=True,\n",
    "    include_distances=True,\n",
    "    include_normalized=True,\n",
    "    segmentation_strategy=\"split_on_label\",\n",
    "    segmentation_splitter_label=\"step_type\",\n",
    "    segmentation_window=10,\n",
    "    segmentation_window_label=\"weight_transfer_type\",\n",
    ")\n",
    "\n",
    "db.write_dataset_to_csv(\n",
    "    csv_location=merged_annotation_output_directory,\n",
    "    formatted_dataset=formatted_dataset,\n",
    "    filename=\"pooled_angles_distances_last_10_frames\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten columns over 10 frame window on step type (arbitrary start / end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = data_builder.BuildAndFormatDatasetJob()\n",
    "dataset = db.build_dataset_from_data_files(\n",
    "    annotations_data_directory=source_annotations_directory,\n",
    "    sequence_data_directory=sequence_data_directory,\n",
    "    limit=None,\n",
    ")\n",
    "\n",
    "formatted_dataset = db.format_dataset(\n",
    "    dataset=dataset,\n",
    "    pool_frame_data_by_clip=True,\n",
    "    decimal_precision=4,\n",
    "    include_unlabeled_data=True,\n",
    "    include_angles=True,\n",
    "    include_distances=True,\n",
    "    include_normalized=True,\n",
    "    segmentation_strategy=\"split_on_label\",\n",
    "    segmentation_splitter_label=\"step_type\",\n",
    "    segmentation_window=10,\n",
    "    segmentation_window_label=\"weight_transfer_type\",\n",
    ")\n",
    "\n",
    "db.write_dataset_to_csv(\n",
    "    csv_location=merged_annotation_output_directory,\n",
    "    formatted_dataset=formatted_dataset,\n",
    "    filename=\"pooled_angles_distances_last_10_frames\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten on a 10 frame window based on complete training examples (the end of the example will flatten the previous 10 frames into a training row0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = data_builder.BuildAndFormatDatasetJob()\n",
    "dataset = db.build_dataset_from_data_files(\n",
    "    annotations_data_directory=source_annotations_directory,\n",
    "    sequence_data_directory=sequence_data_directory,\n",
    "    limit=None,\n",
    ")\n",
    "\n",
    "formatted_dataset = db.format_dataset(\n",
    "    dataset=dataset,\n",
    "    pool_frame_data_by_clip=False,\n",
    "    decimal_precision=4,\n",
    "    include_unlabeled_data=True,\n",
    "    include_angles=True,\n",
    "    include_distances=True,\n",
    "    include_normalized=True,\n",
    "    segmentation_strategy=\"flatten_on_example\",\n",
    "    segmentation_splitter_label=\"step_type\",\n",
    "    segmentation_window=10,\n",
    "    segmentation_window_label=\"weight_transfer_type\",\n",
    ")\n",
    "\n",
    "db.write_dataset_to_csv(\n",
    "    csv_location=merged_annotation_output_directory,\n",
    "    formatted_dataset=formatted_dataset,\n",
    "    filename=\"flatten_on_example_10_frames_2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten on a 25 frame window based on complete training examples (the end of the example will flatten the previous 25 frames into a training row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = data_builder.BuildAndFormatDatasetJob()\n",
    "dataset = db.build_dataset_from_data_files(\n",
    "    annotations_data_directory=source_annotations_directory,\n",
    "    sequence_data_directory=sequence_data_directory,\n",
    "    limit=None,\n",
    ")\n",
    "\n",
    "formatted_dataset = db.format_dataset(\n",
    "    dataset=dataset,\n",
    "    pool_frame_data_by_clip=False,\n",
    "    decimal_precision=4,\n",
    "    include_unlabeled_data=True,\n",
    "    include_angles=True,\n",
    "    include_distances=True,\n",
    "    include_normalized=True,\n",
    "    segmentation_strategy=\"flatten_on_example\",\n",
    "    segmentation_splitter_label=\"step_type\",\n",
    "    segmentation_window=25,\n",
    "    segmentation_window_label=\"weight_transfer_type\",\n",
    ")\n",
    "\n",
    "db.write_dataset_to_csv(\n",
    "    csv_location=merged_annotation_output_directory,\n",
    "    formatted_dataset=formatted_dataset,\n",
    "    filename=\"preprocessed_flatten_on_example_25_frames_2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset with all frames as rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = data_builder.BuildAndFormatDatasetJob()\n",
    "dataset = db.build_dataset_from_data_files(\n",
    "    annotations_data_directory=source_annotations_directory,\n",
    "    sequence_data_directory=sequence_data_directory,\n",
    "    limit=None,\n",
    ")\n",
    "\n",
    "formatted_dataset = db.format_dataset(\n",
    "    dataset=dataset,\n",
    "    pool_frame_data_by_clip=False,\n",
    "    decimal_precision=4,\n",
    "    include_unlabeled_data=True,\n",
    "    include_angles=True,\n",
    "    include_distances=True,\n",
    "    include_normalized=True,\n",
    "    segmentation_strategy=\"none\",\n",
    "    segmentation_splitter_label=\"step_type\",\n",
    "    segmentation_window=25,\n",
    "    segmentation_window_label=\"weight_transfer_type\",\n",
    ")\n",
    "\n",
    "db.write_dataset_to_csv(\n",
    "    csv_location=merged_annotation_output_directory,\n",
    "    formatted_dataset=formatted_dataset,\n",
    "    filename=\"preprocessed_all_rows.csv\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
